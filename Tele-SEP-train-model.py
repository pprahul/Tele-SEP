# -*- coding: utf-8 -*-
"""GBC_sepsis-RASPRO-with-delta-features-SHAP-analysis-v1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15d28Wjo5zXEYNhM8cmgvzrYb837gtISk
"""

import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt

## Quantization based on National Early Warning Score 2 (NEWS2)
# https://www.a4medicine.co.uk/national-early-warning-score-news-2/#
def quantize_news2(df):
    #HR ranges
    df.loc[(df['HR'] <= 40), 'HR'] = -3
    df.loc[(df['HR'] > 40) & (df['HR'] <=50) , 'HR'] = -1
    df.loc[(df['HR'] > 50) & (df['HR'] <=90) , 'HR'] = 0
    df.loc[(df['HR'] > 90) & (df['HR'] <=110) , 'HR'] = 1
    df.loc[(df['HR'] > 110) & (df['HR'] <=130) , 'HR'] = 2
    df.loc[(df['HR'] > 130), 'HR'] = 3
    
    #O2Sat ranges
    df.loc[(df['O2Sat'] <= 91),'O2Sat'] = 3
    df.loc[(df['O2Sat'] > 91) & (df['O2Sat'] <=93) , 'O2Sat'] = 2
    df.loc[(df['O2Sat'] > 93) & (df['O2Sat'] <=95) , 'O2Sat'] = 1
    df.loc[(df['O2Sat'] > 95),'O2Sat'] = 0
   
    #SBP ranges
    df.loc[(df['SBP'] <= 90), 'SBP'] = -3
    df.loc[(df['SBP'] > 90) & (df['SBP'] <=100) , 'SBP'] = -2
    df.loc[(df['SBP'] > 100) & (df['SBP'] <=110) , 'SBP'] = -1
    df.loc[(df['SBP'] > 110) & (df['SBP'] <=219) , 'SBP'] = 0
    df.loc[(df['SBP'] >219), 'SBP'] = 3
    
    #Resp rate
    df.loc[(df['Resp'] <= 8), 'Resp'] = -3
    df.loc[(df['Resp'] > 8) & (df['Resp'] <=11) , 'Resp'] = -1
    df.loc[(df['Resp'] > 11) & (df['Resp'] <=20) , 'Resp'] = 0
    df.loc[(df['Resp'] > 20) & (df['Resp'] <=24) , 'Resp'] = 2
    df.loc[(df['Resp'] >24) , 'Resp'] = 3
    
    #Temp ranges
    df.loc[(df['Temp'] <= 35),'Temp'] = -3
    df.loc[(df['Temp'] > 35) & (df['Temp'] <=36) , 'Temp'] = -1
    df.loc[(df['Temp'] > 36) & (df['Temp'] <=38) , 'Temp'] = 0
    df.loc[(df['Temp'] > 38) & (df['Temp'] <=39) , 'Temp'] = 1
    df.loc[(df['Temp'] > 39),'Temp'] = 2        
            
    return df

VERBOSE = 0
QUANTIZE = 0

time_window_hr = 3
prediction_time_hr = 5
nonsepsis_start_time_hr = 0

monitoring_window_start = nonsepsis_start_time_hr
monitoring_window_end = nonsepsis_start_time_hr + time_window_hr

nonsepsis_dir='CinC2019 Dataset/training_setA/trainingA_nonsepsis'

nonsepsis = []
features = pd.DataFrame()
count = 1

#browsing through non-sepsis data 
for filename in os.listdir(nonsepsis_dir):
        
    # read file as pandas dataframe
    df = pd.read_csv(nonsepsis_dir+'/'+filename,sep='|')
    
    if df.index[-1] >= 15:
        print(count)
        #df_features = df[['HR','O2Sat','SBP','MAP','DBP','Resp','SepsisLabel']]
        df_features = df[['O2Sat','RR']]

        df_features_12h = df_features.iloc[monitoring_window_start:monitoring_window_end,:]
        #print(df_features_12h)
        df_features_12h.fillna(method='ffill', inplace=True, limit=2) #replacing Nan with previous value
        df_features_12h.fillna(method='bfill', inplace=True, limit=2) #replacing Nan with next value (if first row is Nan)
        #print(df_features_12h)
        if (df_features_12h.isnull().values.any() == True):
            continue
        
        if QUANTIZE == 1:
            #Quantizing according to NEWS2
            df_features_12h = quantize_news2(df_features_12h)
        
        
        # Feature construction
        features = pd.DataFrame(columns=df_features_12h.columns)
        features = features.append(df_features_12h.iloc[0])
        
        if (df_features_12h.shape[0] > 1):
            i = 1
            
            while(i < df_features_12h.shape[0]): # find delt from first observation row and rate of change
                delta_from_first_obs = features.iloc[0] - df_features_12h.iloc[i]
                rate_delta_from_first_obs = delta_from_first_obs / i # rate of change
                
                features = features.append(delta_from_first_obs, ignore_index=True)
                features = features.append(rate_delta_from_first_obs, ignore_index=True)
                i+=1
            
            i=2
            while(i < df_features_12h.shape[0]):  # find delt between consecutive observations
                delta_consecutive = df_features_12h.iloc[i-1] - df_features_12h.iloc[i]
                #print(delta_consecutive)
                features = features.append(delta_consecutive, ignore_index=True)
                i+=1
                
        features = features.append(df_features_12h.var(axis=0), ignore_index=True)
                
        
        nonsepsis.append(features.to_numpy())
        
        if count==600:
          #  break
        count+=1
    else:
        print (filename)

nonsepsis = np.array(nonsepsis)    
print(nonsepsis.shape)
#array_has_nan = np.isnan(nonsepsis)
#print(array_has_nan)
print(nonsepsis[2])

"""nonsepsis[nonsepsis=0] = 'A'
nonsepsis[nonsepsis=1] = 'A+'
nonsepsis[nonsepsis=] = 'A'
nonsepsis[nonsepsis=0] = 'A'

"""

sepsis_dir='CinC2019 Dataset/training_setA/trainingA_sepsis_15h'

sepsis = []

count = 0
for filename in os.listdir(sepsis_dir):
    print (count)
    # read file as pandas dataframe
    df = pd.read_csv(sepsis_dir+'/'+filename,sep='|')
    #df_features = df[['HR','O2Sat','SBP','MAP','DBP','Resp','SepsisLabel']]
    df_features = df[['O2Sat','Resp','SepsisLabel']]
    i = df_features[df_features['SepsisLabel']==1]
    df_features = df_features.drop('SepsisLabel',axis = 1)
    
    sepsis_start_time_hr = i.index[0]
    monitoring_window_start = sepsis_start_time_hr - prediction_time_hr - time_window_hr
    monitoring_window_end = monitoring_window_start + time_window_hr
    
    df_features_12h = df_features.iloc[monitoring_window_start:monitoring_window_end,:]
    df_features_12h.fillna(method='ffill', inplace=True, limit=2) #replacing Nan with previous value
    df_features_12h.fillna(method='bfill', inplace=True, limit=2) #replacing Nan with next value (if first row is Nan)
    #print(sepsis_start_time_hr,filename, df_features_12h)
    
    if (df_features_12h.isnull().values.any() == True):
            continue
    
    if QUANTIZE == 1:
        #Quantizing according to NEWS2
        df_features_12h = quantize_news2(df_features_12h)
    
    # Feature construction
    features = pd.DataFrame(columns=df_features_12h.columns)
    features = features.append(df_features_12h.iloc[0])
    #print(features)

    if (df_features_12h.shape[0] > 1):
        i = 1
        
        while(i < df_features_12h.shape[0]): # find delt from first observation row and rate of change
            delta_from_first_obs = features.iloc[0] - df_features_12h.iloc[i]
            rate_delta_from_first_obs = delta_from_first_obs / i # rate of change
            
            features = features.append(delta_from_first_obs, ignore_index=True)
            features = features.append(rate_delta_from_first_obs, ignore_index=True)
            i+=1
        

        i=2
        while(i < df_features_12h.shape[0]):
            delta_consecutive = df_features_12h.iloc[i-1] - df_features_12h.iloc[i]
            features = features.append(delta_consecutive, ignore_index=True)
            i+=1
            
    features = features.append(df_features_12h.var(axis=0), ignore_index=True)
    
    sepsis.append(features.to_numpy())
    
    count+=1
    
sepsis = np.array(sepsis)    
print(sepsis.shape)

print(sepsis[1])
print(nonsepsis[1])
if VERBOSE == 1:
    nonsepsis_hr_flat = np.reshape(nonsepsis[:,:,4],(nonsepsis.shape[0]*nonsepsis.shape[1],1))
    sepsis_hr_flat = np.reshape(sepsis[:,:,4],(sepsis.shape[0]*sepsis.shape[1],1))
    
    bins_list = range(5,40,2)
    plt.hist(nonsepsis_hr_flat, bins=5, rwidth=0.8)
    plt.ylim((0,250))
    plt.xlim((5,40))
    plt.show()

    
    plt.hist(sepsis_hr_flat, bins=5, rwidth=0.8)
    plt.ylim((0,250))
    plt.xlim((5,40))
    plt.show()

if VERBOSE == 1:
    count_hrs_NEWS2_thresh_nonsepsis = np.count_nonzero(nonsepsis_hr_flat >= 5, axis=0)
    print(count_hrs_NEWS2_thresh_nonsepsis)

    count_hrs_NEWS2_thresh_sepsis = np.count_nonzero(sepsis_hr_flat >= 5, axis=0)
    print(count_hrs_NEWS2_thresh_sepsis)

    FP = count_hrs_NEWS2_thresh_nonsepsis
    TP = count_hrs_NEWS2_thresh_sepsis

    Precision = TP / (TP+FP)
    Recall = TP / sepsis_hr_flat.shape[0]

    print('Precision: ', Precision, '\nRecall: ', Recall)

if VERBOSE == 1:
    NEWSaggregate_patient_nonsepsis = np.sum(nonsepsis[:,:,5], axis=1)
    NEWSaggregate_nonsepsis = np.sum(NEWSaggregate_patient_nonsepsis)
    print(NEWSaggregate_nonsepsis)

    NEWSaggregate_patient_sepsis = np.sum(sepsis[:,:,5], axis=1)
    NEWSaggregate_sepsis = np.sum(NEWSaggregate_patient_sepsis)
    print(NEWSaggregate_sepsis)
    print(max(NEWSaggregate_patient_sepsis), min(NEWSaggregate_patient_sepsis))

    bins_list = range(0,60,1)

    plt.hist(NEWSaggregate_patient_nonsepsis, bins=bins_list, rwidth=0.9)
    plt.ylim((0,220))
    plt.xlim((0,20))
    plt.show()

    plt.hist(NEWSaggregate_patient_sepsis, bins=bins_list, rwidth=0.9)
    plt.ylim((0,220))
    plt.xlim((0,20))
    plt.show()

# create label array because all labels are zero
sepsis_label = np.zeros((nonsepsis.shape[0],1))
sepsis_label = np.append(sepsis_label, np.ones((sepsis.shape[0],1)), axis=0)
print(['label array:' , sepsis_label.shape])
print(sepsis_label.shape)
#combine datasets
combined_featureset = np.append(nonsepsis, sepsis, axis=0)
#print(combined_featureset[6])

import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(combined_featureset,  np.ravel(sepsis_label), test_size=0.2, random_state=0)

print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

print(np.count_nonzero(y_train))
print(np.count_nonzero(y_test))

#print(X_test[1])
#print(X_train[1])



n_train = X_train.shape[0]
input_shape = X_train.shape[1]*X_train.shape[2]
X_train = X_train.reshape(n_train, input_shape)

n_test = X_test.shape[0]
X_test = X_test.reshape(n_test, input_shape)

#y_train = np.reshape(y_train, (-1,1))
#y_test = np.reshape(y_test, (-1,1))
print(y_train.shape)

# xgboost for classification
from numpy import asarray
from numpy import mean
from numpy import std
from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from matplotlib import pyplot

'''
# evaluate the model
model = XGBClassifier()
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
n_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')
print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))


# make a single prediction
##row = [2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]
#row = asarray(row).reshape((1, len(row)))
'''

import sys
import math
 
import numpy as np
from sklearn.model_selection import GridSearchCV 
 
sys.path.append('xgboost/wrapper/')
import xgboost as xgb
 
 
class XGBoostClassifier():
    def __init__(self, num_boost_round=10, **params):
        self.clf = None
        self.num_boost_round = num_boost_round
        self.params = params
        self.params.update({'objective': 'multi:softprob'})
        #self.params.update({'objective': 'binary:logistic'})
 
    def fit(self, X, y, num_boost_round=None):
        num_boost_round = num_boost_round or self.num_boost_round
        self.label2num = {label: i for i, label in enumerate(sorted(set(y)))}
        dtrain = xgb.DMatrix(X, label=[self.label2num[label] for label in y])
        self.clf = xgb.train(params=self.params, dtrain=dtrain, num_boost_round=num_boost_round)
 
    def predict(self, X):
        num2label = {i: label for label, i in self.label2num.items()}
        Y = self.predict_proba(X)
        y = np.argmax(Y, axis=1)
        return np.array([num2label[i] for i in y])
 
    def predict_proba(self, X):
        dtest = xgb.DMatrix(X)
        return self.clf.predict(dtest)
 
    def score(self, X, y):
        Y = self.predict_proba(X)
        return 1 / logloss(y, Y)
 
    def get_params(self, deep=True):
        return self.params
 
    def set_params(self, **params):
        if 'num_boost_round' in params:
            self.num_boost_round = params.pop('num_boost_round')
        if 'objective' in params:
            del params['objective']
        self.params.update(params)
        return self
    
    
def logloss(y_true, Y_pred):
    label2num = dict((name, i) for i, name in enumerate(sorted(set(y_true))))
    return -1 * sum(math.log(y[label2num[label]]) if y[label2num[label]] > 0 else -np.inf for y, label in zip(Y_pred, y_true)) / len(Y_pred)

clf = XGBoostClassifier(
        eval_metric = 'auc',
        num_class = 2,
        nthread = 4,
        silent = 0,
        )
'''
parameters = {
    'num_boost_round': [100, 250, 500],
    'eta': [0.05, 0.1, 0.3],
    'max_depth': [6, 9, 12],
    'subsample': [0.9, 1.0],
    'colsample_bytree': [0.9, 1.0],
    'objective': ['binary:logistic']
}
'''
parameters = {
    'num_boost_round': [50, 100, 250],
    'eta': [0.01, 0.05, 0.1],
    'max_depth': [3, 6, 9, 12],
    'subsample': [0.9, 1.0],
    'colsample_bytree': [0.3, 0.5, 0.9, 1.0],
}
gridModel = GridSearchCV(clf, parameters, n_jobs=-1, cv=3, verbose=3)

gridModel.fit(X_train, y_train)

import pickle

# save the model to disk
model_filename = 'XGB-Models/' + 'XGB-Model-Temp-trainedonQuadset-Feb22-L' + str(prediction_time_hr) + '-M' + str(time_window_hr) +'-trainedagain_Feb22_for SHap'+ '.sav'
pickle.dump(gridModel, open(model_filename, 'wb'))

import pickle
# load the model from disk
loaded_model = pickle.load(open('XGB-Models/XGB-Model-Temp-trainedonQuadset-Feb22-L6-M4-trainedagain_Feb22_for SHap.sav', 'rb'))

# print best parameter after tuning 
print(loaded_model.best_params_) 
  
# print how our model looks after hyper-parameter tuning 
print(loaded_model.best_estimator_)
 
# make predictions for test data
y_pred_proba = loaded_model.predict_proba(X_test)
y_pred = loaded_model.predict(X_test)

# print classification report 
print(classification_report(y_test, y_pred)) 

#confusion matrix
cnf_matrix = confusion_matrix(y_test, y_pred)
print(cnf_matrix)
#print(y_pred_proba)

from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score

## Plot ROC-AUC curves
# generate a no skill prediction (majority class)
ns_probs = [0 for _ in range(len(y_test))]
# predict probabilities
lr_probs = loaded_model.predict_proba(X_test)
# keep probabilities for the positive outcome only
lr_probs = lr_probs[:, 1]
# calculate scores
ns_auc = roc_auc_score(y_test, ns_probs)
lr_auc = roc_auc_score(y_test, lr_probs)
# summarize scores
print('No Skill: ROC AUC=%.3f' % (ns_auc))
print('Logistic: ROC AUC=%.3f' % (lr_auc))
# calculate roc curves
ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)
lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)
# plot the roc curve for the model
pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
pyplot.plot(lr_fpr, lr_tpr, marker='.', label='GBC')
# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
# show the legend
pyplot.legend()
# show the plot
pyplot.show()

# precision-recall curve and f1
from sklearn.datasets import make_classification
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import f1_score
from sklearn.metrics import auc
from matplotlib import pyplot

lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)
lr_f1, lr_auc = f1_score(y_test, y_pred), auc(lr_recall, lr_precision)
# summarize scores
print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))
# plot the precision-recall curves
no_skill = len(y_test[y_test==1]) / len(y_test)
pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')
pyplot.plot(lr_recall, lr_precision, marker='.', label='Logistic')
# axis labels
pyplot.xlabel('Recall')
pyplot.ylabel('Precision')
# show the legend
pyplot.legend()
# show the plot
pyplot.show()

import os
#os.system('say "Completed"')
os.system('afplay bell-ringing-05.aiff')

from xgboost import plot_tree

best_params = {
    'num_boost_round': 50,
    'eta': 0.1,
    'max_depth': 12,
    'subsample': 1.0,
    'colsample_bytree': 0.3
}

model = XGBClassifier(params=best_params)
model.fit(X_train, y_train)

import shap

'''
column_headers = ['HR','O2Sat','SBP','Resp','Temp',
                  'HR-Hr2DiffFrom1','O2Sat-Hr2DiffFrom1','SBP-Hr2DiffFrom1','Resp-Hr2DiffFrom1','Temp-Hr2DiffFrom1',
                  'HR-Hr2RateDiffFrom1','O2Sat-Hr2RateDiffFrom1','SBP-Hr2RateDiffFrom1','Resp-Hr2RateDiffFrom1','Temp-Hr2RateDiffFrom1',
                  'HR-Hr3DiffFrom1','O2Sat-Hr3DiffFrom1','SBP-Hr3DiffFrom1','Resp-Hr3DiffFrom1','Temp-Hr3DiffFrom1',
                  'HR-Hr3RateDiffFrom1','O2Sat-Hr3RateDiffFrom1','SBP-Hr3RateDiffFrom1','Resp-Hr3RateDiffFrom1','Temp-Hr3RateDiffFrom1',
                  'HR-Hr4DiffFrom1','O2Sat-Hr4DiffFrom1','SBP-Hr4DiffFrom1','Resp-Hr4DiffFrom1','Temp-Hr4DiffFrom1',
                  'HR-Hr4RateDiffFrom1','O2Sat-Hr4RateDiffFrom1','SBP-Hr4RateDiffFrom1','Resp-Hr4RateDiffFrom1','Temp-Hr4RateDiffFrom1',
                  'HR-Hr5DiffFrom1','O2Sat-Hr5DiffFrom1','SBP-Hr5DiffFrom1','Resp-Hr5DiffFrom1','Temp-Hr5DiffFrom1',
                  'HR-Hr5RateDiffFrom1','O2Sat-Hr5RateDiffFrom1','SBP-Hr5RateDiffFrom1','Resp-Hr5RateDiffFrom1','Temp-Hr5RateDiffFrom1',
                  'HR-Hr6DiffFrom1','O2Sat-Hr6DiffFrom1','SBP-Hr6DiffFrom1','Resp-Hr6DiffFrom1','Temp-Hr6DiffFrom1',
                  'HR-Hr6RateDiffFrom1','O2Sat-Hr6RateDiffFrom1','SBP-Hr6RateDiffFrom1','Resp-Hr6RateDiffFrom1','Temp-Hr6RateDiffFrom1',
                  'HR-Hr3DiffFrom2', 'O2Sat-Hr3DiffFrom2', 'SBP-Hr3DiffFrom2', 'Resp-Hr3DiffFrom2', 'Temp-Hr3DiffFrom2', 
                  'HR-Hr4DiffFrom3', 'O2Sat-Hr4DiffFrom3', 'SBP-Hr4DiffFrom3', 'Resp-Hr4DiffFrom3', 'Temp-Hr4DiffFrom3', 
                  'HR-Hr5DiffFrom4', 'O2Sat-Hr5DiffFrom4', 'SBP-Hr5DiffFrom4', 'Resp-Hr5DiffFrom4', 'Temp-Hr5DiffFrom4', 
                  'HR-Hr6DiffFrom5', 'O2Sat-Hr6DiffFrom5', 'SBP-Hr6DiffFrom5', 'Resp-Hr6DiffFrom5', 'Temp-Hr6DiffFrom5', 
                  'HR-Variance', 'O2Sat-Variance', 'SBP-Variance', 'Resp-Variance', 'Temp-Variance']

column_headers = ['HR','O2Sat','SBP','Resp','Temp',
                  'HR-Hr2DiffFrom1','O2Sat-Hr2DiffFrom1','SBP-Hr2DiffFrom1','Resp-Hr2DiffFrom1','Temp-Hr2DiffFrom1',
                  'HR-Hr2RateDiffFrom1','O2Sat-Hr2RateDiffFrom1','SBP-Hr2RateDiffFrom1','Resp-Hr2RateDiffFrom1','Temp-Hr2RateDiffFrom1',
                  'HR-Hr3DiffFrom1','O2Sat-Hr3DiffFrom1','SBP-Hr3DiffFrom1','Resp-Hr3DiffFrom1','Temp-Hr3DiffFrom1',
                  'HR-Hr3RateDiffFrom1','O2Sat-Hr3RateDiffFrom1','SBP-Hr3RateDiffFrom1','Resp-Hr3RateDiffFrom1','Temp-Hr3RateDiffFrom1',
                  'HR-Hr4DiffFrom1','O2Sat-Hr4DiffFrom1','SBP-Hr4DiffFrom1','Resp-Hr4DiffFrom1','Temp-Hr4DiffFrom1',
                  'HR-Hr4RateDiffFrom1','O2Sat-Hr4RateDiffFrom1','SBP-Hr4RateDiffFrom1','Resp-Hr4RateDiffFrom1','Temp-Hr4RateDiffFrom1',
                  'HR-Hr3DiffFrom2', 'O2Sat-Hr3DiffFrom2', 'SBP-Hr3DiffFrom2', 'Resp-Hr3DiffFrom2', 'Temp-Hr3DiffFrom2', 
                  'HR-Hr4DiffFrom3', 'O2Sat-Hr4DiffFrom3', 'SBP-Hr4DiffFrom3', 'Resp-Hr4DiffFrom3', 'Temp-Hr4DiffFrom3', 
                  'HR-Variance', 'O2Sat-Variance', 'SBP-Variance', 'Resp-Variance', 'Temp-Variance']


column_headers = ['H1-HR','H1-O2Sat','H1-SBP','H1-Resp','H1-Temp',
                 'H2-HR','H2-O2Sat','H2-SBP','H2-Resp','H2-Temp',
                 'H3-HR','H3-O2Sat','H3-SBP','H3-Resp','H3-Temp',
                 'H4-HR','H4-O2Sat','H4-SBP','H4-Resp','H4-Temp',
                 'H5-HR','H5-O2Sat','H5-SBP','H5-Resp','H5-Temp',
                 'H6-HR','H6-O2Sat','H6-SBP','H6-Resp','H6-Temp']


column_headers = ['HR','O2Sat','Resp','Temp',
                  'HR-Hr2DiffFrom1','O2Sat-Hr2DiffFrom1','Resp-Hr2DiffFrom1','Temp-Hr2DiffFrom1',
                  'HR-Hr2RateDiffFrom1','O2Sat-Hr2RateDiffFrom1','Resp-Hr2RateDiffFrom1','Temp-Hr2RateDiffFrom1',
                  'HR-Hr3DiffFrom1','O2Sat-Hr3DiffFrom1','Resp-Hr3DiffFrom1','Temp-Hr3DiffFrom1',
                  'HR-Hr3RateDiffFrom1','O2Sat-Hr3RateDiffFrom1','Resp-Hr3RateDiffFrom1','Temp-Hr3RateDiffFrom1',
                  'HR-Hr4DiffFrom1','O2Sat-Hr4DiffFrom1','Resp-Hr4DiffFrom1','Temp-Hr4DiffFrom1',
                  'HR-Hr4RateDiffFrom1','O2Sat-Hr4RateDiffFrom1','Resp-Hr4RateDiffFrom1','Temp-Hr4RateDiffFrom1',
                  'HR-Hr5DiffFrom1','O2Sat-Hr5DiffFrom1','Resp-Hr5DiffFrom1','Temp-Hr5DiffFrom1',
                  'HR-Hr5RateDiffFrom1','O2Sat-Hr5RateDiffFrom1','Resp-Hr5RateDiffFrom1','Temp-Hr5RateDiffFrom1',
                  'HR-Hr6DiffFrom1','O2Sat-Hr6DiffFrom1','Resp-Hr6DiffFrom1','Temp-Hr6DiffFrom1',
                  'HR-Hr6RateDiffFrom1','O2Sat-Hr6RateDiffFrom1','Resp-Hr6RateDiffFrom1','Temp-Hr6RateDiffFrom1',
                  'HR-Hr3DiffFrom2', 'O2Sat-Hr3DiffFrom2', 'Resp-Hr3DiffFrom2', 'Temp-Hr3DiffFrom2', 
                  'HR-Hr4DiffFrom3', 'O2Sat-Hr4DiffFrom3', 'Resp-Hr4DiffFrom3', 'Temp-Hr4DiffFrom3', 
                  'HR-Hr5DiffFrom4', 'O2Sat-Hr5DiffFrom4', 'Resp-Hr5DiffFrom4', 'Temp-Hr5DiffFrom4', 
                  'HR-Hr6DiffFrom5', 'O2Sat-Hr6DiffFrom5', 'Resp-Hr6DiffFrom5', 'Temp-Hr6DiffFrom5', 
                  'HR-Variance', 'O2Sat-Variance', 'Resp-Variance', 'Temp-Variance']

column_headers = ['HR','O2Sat','Resp','Temp',
                  'HR:h2-h1','O2Sat:h2-h1','Resp:h2-h1','Temp:h2-h1',
                  'HR:Hr2RateDiffFrom1','O2Sat-Hr2RateDiffFrom1','Resp-Hr2RateDiffFrom1','Temp-Hr2RateDiffFrom1',
                  'HR-Hr3DiffFrom1','O2Sat-Hr3DiffFrom1','Resp-Hr3DiffFrom1','Temp-Hr3DiffFrom1',
                  'HR-Hr3RateDiffFrom1','O2Sat-Hr3RateDiffFrom1','Resp-Hr3RateDiffFrom1','Temp-Hr3RateDiffFrom1',
                  'HR-Hr4DiffFrom1','O2Sat-Hr4DiffFrom1','Resp-Hr4DiffFrom1','Temp-Hr4DiffFrom1',
                  'HR-Hr4RateDiffFrom1','O2Sat-Hr4RateDiffFrom1','Resp-Hr4RateDiffFrom1','Temp-Hr4RateDiffFrom1',
                  'HR-Hr5DiffFrom1','O2Sat-Hr5DiffFrom1','Resp-Hr5DiffFrom1','Temp-Hr5DiffFrom1',
                  'HR-Hr5RateDiffFrom1','O2Sat-Hr5RateDiffFrom1','Resp-Hr5RateDiffFrom1','Temp-Hr5RateDiffFrom1',
                  'HR-Hr6DiffFrom1','O2Sat-Hr6DiffFrom1','Resp-Hr6DiffFrom1','Temp-Hr6DiffFrom1',
                  'HR-Hr6RateDiffFrom1','O2Sat-Hr6RateDiffFrom1','Resp-Hr6RateDiffFrom1','Temp-Hr6RateDiffFrom1',
                  'HR-Hr3DiffFrom2', 'O2Sat-Hr3DiffFrom2', 'Resp-Hr3DiffFrom2', 'Temp-Hr3DiffFrom2', 
                  'HR-Hr4DiffFrom3', 'O2Sat-Hr4DiffFrom3', 'Resp-Hr4DiffFrom3', 'Temp-Hr4DiffFrom3', 
                  'HR-Hr5DiffFrom4', 'O2Sat-Hr5DiffFrom4', 'Resp-Hr5DiffFrom4', 'Temp-Hr5DiffFrom4', 
                  'HR-Hr6DiffFrom5', 'O2Sat-Hr6DiffFrom5', 'Resp-Hr6DiffFrom5', 'Temp-Hr6DiffFrom5', 
                  'HR-Variance', 'O2Sat-Variance', 'Resp-Variance', 'Temp-Variance']


'''
column_headers = ['HR','O2Sat','Resp','Temp',
                  'HR:h2-h1','O2Sat:h2-h1','Resp:h2-h1','Temp:h2-h1',
                  'HR:rateofchange_h1toh2','O2Sat:rateofchange_h1toh2','Resp:rateofchange_h1toh2','Temp:rateofchange_h1toh2',
                  'HR:h3-h1','O2Sat:h3-h1','Resp:h3-h1','Temp:h3-h1',
                  'HR:rateofchange_h1toh3','O2Sat:rateofchange_h1toh3','Resp:rateofchange_h1toh3','Temp:rateofchange_h1toh3',
                  'HR:h4-h1','O2Sat:h4-h1','Resp:h4-h1','Temp:h4-h1',
                  'HR:rateofchange_h1toh4','O2Sat:rateofchange_h1toh4','Resp:rateofchange_h1toh4','Temp:rateofchange_h1toh4',
                  'HR:h3-h2', 'O2Sat:h3-h2', 'Resp:h3-h2', 'Temp:h3-h2', 
                  'HR:h4-h3', 'O2Sat:h4-h3', 'Resp:h4-h3', 'Temp:h4-h3', 
                  'HR-Variance', 'O2Sat-Variance', 'Resp-Variance', 'Temp-Variance']


X_train_df = pd.DataFrame(X_train, columns=column_headers)
X_test_df = pd.DataFrame(X_test, columns=column_headers)


# explain the model's predictions using SHAP
# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_train_df)

# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)
shap.force_plot(explainer.expected_value, shap_values[0,:], X_train_df.iloc[0,:], matplotlib=True)

# create a dependence plot to show the effect of a single feature across the whole dataset
shap.dependence_plot("Temp", shap_values, X_train_df)

# summarize the effects of all the features
shap.summary_plot(shap_values, X_train_df)

shap.summary_plot(shap_values, X_train_df, plot_type="bar")